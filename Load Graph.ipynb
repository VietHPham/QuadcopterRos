{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pi/berryconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/pi/berryconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load graph\n",
      "WARNING:tensorflow:From <ipython-input-1-8c6cb5db44bc>:6: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "[]\n",
      "['Const', 'Identity', 'Placeholder', 'Const', 'Identity', 'Const', 'Identity', 'Sub', 'Cast', 'Const', 'Add', 'RealDiv', 'Sqrt', 'RealDiv', 'Const', 'Minimum', 'Const', 'Maximum', 'Const', 'Identity', 'Const', 'Identity', 'MatMul', 'BiasAdd', 'Sigmoid', 'Mul', 'Const', 'Identity', 'Const', 'Identity', 'MatMul', 'BiasAdd', 'Sigmoid', 'Mul', 'Const', 'Identity', 'Const', 'Identity', 'MatMul', 'BiasAdd', 'Sigmoid', 'Mul', 'Const', 'Identity', 'Const', 'Identity', 'MatMul', 'BiasAdd', 'Sigmoid', 'Mul', 'Const', 'Identity', 'Const', 'Identity', 'MatMul', 'BiasAdd', 'Const', 'Identity', 'Exp', 'Shape', 'Const', 'Const', 'RandomStandardNormal', 'Mul', 'Add', 'Sqrt', 'Mul', 'Add', 'Const', 'Minimum', 'Const', 'Maximum', 'Const', 'RealDiv', 'Identity', 'StopGradient', 'Sub', 'Square', 'Const', 'Mul', 'RealDiv', 'Const', 'Log', 'Const', 'Mul', 'Sub', 'Const', 'Mul', 'Sub', 'Identity', 'Const', 'Identity', 'Const', 'Identity', 'MatMul', 'BiasAdd', 'Identity']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "GRAPH_PB_PATH = './qw_w_scratch_1-0.bytes'\n",
    "with tf.Session() as sess:\n",
    "    print(\"load graph\")\n",
    "    with gfile.FastGFile(GRAPH_PB_PATH,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    sess.graph.as_default()\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "    graph_nodes=[n for n in graph_def.node]\n",
    "    names = []\n",
    "    ops = []\n",
    "    inputs = []\n",
    "    for t in graph_nodes:\n",
    "        names.append(t.name)\n",
    "        ops.append(t.op)\n",
    "        inputs.append(t.input)\n",
    "    print(names)\n",
    "    print(ops)\n",
    "    #print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    # We load the protobuf file from the disk and parse it to retrieve the \n",
    "    # unserialized graph_def\n",
    "    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # Then, we import the graph_def into a new Graph and returns it \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use our \"load_graph\" function\n",
    "graph = load_graph(GRAPH_PB_PATH)\n",
    "\n",
    "# We can verify that we can access the list of operations in the graph\n",
    "#for op in graph.get_operations():\n",
    "    #print([op.name,op.values()])\n",
    "    # prefix/Placeholder/inputs_placeholder\n",
    "    # ...\n",
    "    # prefix/Accuracy/predictions\n",
    "    \n",
    "# We access the input and output nodes \n",
    "x = graph.get_tensor_by_name('prefix/vector_observation:0')\n",
    "y = graph.get_tensor_by_name('prefix/action:0')\n",
    "\n",
    "# We launch a Session\n",
    "# with tf.Session(graph=graph) as sess:\n",
    "#     # Note: we don't nee to initialize/restore anything\n",
    "#     # There is no Variables in this graph, only hardcoded constants \n",
    "#     y_out = sess.run(y, feed_dict={\n",
    "#         x: [[3, 5, 7, 4, 5, 1, 1, 1, 1, 1,3, 5, 7, 4, 5, 1, 1, 1, 1, 1,3, 5, 7, 4, 5, 1]] # < 45\n",
    "#     })\n",
    "#     # I taught a neural net to recognise when a sum of numbers is bigger than 45\n",
    "#     # it should return False in this case\n",
    "#     #print(y_out) # [[ False ]] Yay, it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfile = \"state_history.txt\"\n",
    "thrusts = []\n",
    "states = []\n",
    "with open(resultsfile) as f:\n",
    "        for line in f:\n",
    "            res = eval(line)\n",
    "            thrusts.append(res[\"thrusts\"])\n",
    "            states.append(res[\"states\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "pred_thrusts = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    for state in states:\n",
    "        #x_feed = np.random.rand(26)\n",
    "        #x_feed = [0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,-1,0,1,0,-1]\n",
    "        y_out = sess.run(y, feed_dict={\n",
    "            x: [state]\n",
    "        })\n",
    "        pred_thrusts.append(y_out)\n",
    "        #print(y_out[0][0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "thrusts = np.asarray(thrusts)\n",
    "pred_thrusts = np.asarray(pred_thrusts)\n",
    "errs = []\n",
    "for i in range(len(pred_thrusts)):\n",
    "    errs.append(np.linalg.norm(thrusts[i]-pred_thrusts[i])/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
